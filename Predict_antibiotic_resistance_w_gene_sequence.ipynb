{
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "drscarlat_dzd_data_path = kagglehub.dataset_download('drscarlat/dzd-data')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "kLVw93CRtPVv"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "Vw0KUQx_tPVx"
      },
      "cell_type": "markdown",
      "source": [
        "# GOALS\n",
        "* Binary classification supervised learning\n",
        "* Features: Genomic sequence, 4 letters with their order being very important\n",
        "* Label: True or False - whether resistant or not to an antibiotic (or class of antibiotics)\n",
        "* The genomic string should be tokenized first into the four letters G,C,T,A\n",
        "* The models should be able to deal with text sequences while considering the order\n",
        "* As the dataset is well balanced 0.502 being False with the others being True - the guessing accuracy / sanity check = 50%\n",
        "* Initial RNNs 67%\n",
        "* Conv1D + Bidirectional GRU = 81%\n",
        "* Presenting the model codons instead of nucleotides = 99%\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "ItTN__wCtPVz"
      },
      "cell_type": "code",
      "source": [
        "# IMPORT MODULES\n",
        "\n",
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout, Embedding, LSTM\n",
        "from keras import regularizers, layers, preprocessing\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(os.listdir(\"../input\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BtWJsg1ZtPV0"
      },
      "cell_type": "markdown",
      "source": [
        "# DATA"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "GxEkZTU6tPV0"
      },
      "cell_type": "code",
      "source": [
        "# Load the dataset.npy\n",
        "\n",
        "DataRaw = np.load('../input/dataset.npy', allow_pickle=True)\n",
        "print(type(DataRaw))\n",
        "print(DataRaw.ndim)\n",
        "DataRaw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PK2TinddtPV1"
      },
      "cell_type": "code",
      "source": [
        "# As a dictionary\n",
        "Datadict = DataRaw[()]\n",
        "print(Datadict)\n",
        "\n",
        "# As a dataframe\n",
        "DataDf = pd.DataFrame.from_dict(Datadict)\n",
        "print(DataDf.shape)\n",
        "DataDf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "xSrKl6q7tPV2"
      },
      "cell_type": "code",
      "source": [
        "# Mean  / Max / Min column width\n",
        "\n",
        "DataDf.fillna('').astype(str).apply(lambda x:x.str.len()).max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hg-5Qo0wtPV2"
      },
      "cell_type": "code",
      "source": [
        "# Is the data balanced ?\n",
        "\n",
        "DataDf.groupby('resistant').size().plot.bar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "HbNLpa7ytPV2"
      },
      "cell_type": "code",
      "source": [
        "# Tokenize from characters to integers (sequences and then pad / truncate data)\n",
        "\n",
        "Datatok = DataDf.copy()\n",
        "maxlen = 160 # cut off after this number of characters in a string\n",
        "\n",
        "max_words = 4 # considers only the top number of characters in the dictionary A C T G\n",
        "max_features = max_words\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, char_level=True)\n",
        "tokenizer.fit_on_texts(list(Datatok['genes']))\n",
        "sequences = tokenizer.texts_to_sequences(list(Datatok['genes']))\n",
        "word_index = tokenizer.word_index\n",
        "Xpad = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post', value=0)\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "print('word_index', word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "31ZUQ38_tPV3"
      },
      "cell_type": "code",
      "source": [
        "# Separate the label\n",
        "\n",
        "labels = np.asarray(Datatok['resistant'])\n",
        "print(Xpad.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "U65IappetPV3"
      },
      "cell_type": "code",
      "source": [
        "# Check a sample\n",
        "\n",
        "rowNum = 37149\n",
        "print(Datatok['genes'][rowNum])\n",
        "print(sequences[rowNum])\n",
        "print(Xpad[rowNum])\n",
        "print(labels[rowNum])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_SXrjOYQtPV4"
      },
      "cell_type": "code",
      "source": [
        "# Create train & val and test datasets with inital shuffle (as the original dataset may be arranged)\n",
        "\n",
        "training_samples = int(Xpad.shape[0] * 0.9)\n",
        "# The validation is being taken by keras - below\n",
        "# test = remaining\n",
        "\n",
        "indices = np.arange(Xpad.shape[0])\n",
        "np.random.shuffle(indices) # FOR TESTING PURPOSES comment it out - to keep indices as above\n",
        "\n",
        "Xpad = Xpad[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = Xpad[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_test = Xpad[training_samples: ]\n",
        "y_test = labels[training_samples: ]\n",
        "\n",
        "print('x_train', x_train.shape)\n",
        "print('y_train', y_train.shape)\n",
        "print('x_test', x_test.shape)\n",
        "print('y_test', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uM8Xn0A5tPV4"
      },
      "cell_type": "markdown",
      "source": [
        "# MODELS\n",
        "* There are several models below, all being Keras+TF and able to analyze sequences where order is important\n",
        "* No point in trying any shallow model as they cannot deal with ordered sequences"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "NRZXOEzAtPV4"
      },
      "cell_type": "code",
      "source": [
        "# Model ... 128 CNN window 27 & Bidirectional GRU accuracy =\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(4, 1, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 27, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(9))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(128, 9, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Bidirectional(layers.GRU(32, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "gnzsEAdHtPV4"
      },
      "cell_type": "code",
      "source": [
        "# Train / Validate model\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "epochs = 10,\n",
        "batch_size=32,\n",
        "validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "cGzMp-1ptPV4"
      },
      "cell_type": "code",
      "source": [
        "# Learning curves\n",
        "\n",
        "# VALIDATION LOSS curves\n",
        "\n",
        "plt.clf()\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, (len(history_dict['loss']) + 1))\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# VALIDATION ACCURACY curves\n",
        "\n",
        "plt.clf()\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']\n",
        "epochs = range(1, (len(history_dict['acc']) + 1))\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IjDtD_4rtPV5"
      },
      "cell_type": "code",
      "source": [
        "# Final Predict on test\n",
        "\n",
        "final_predictions = model.predict(x_test)\n",
        "print(final_predictions)\n",
        "\n",
        "# Modify the raw final_predictions - prediction probs  - into 0 and 1\n",
        "# Cutoff point = 0.5\n",
        "\n",
        "Preds = final_predictions.copy()\n",
        "print(len(Preds))\n",
        "\n",
        "Preds[ np.where( Preds >= 0.5 ) ] = 1\n",
        "Preds[ np.where( Preds < 0.5 ) ] = 0\n",
        "print(Preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQu4Y41mtPV5"
      },
      "cell_type": "markdown",
      "source": [
        "# RESULTS\n",
        "* The guessing, sanity check, baseline accuracy is 50% as the dataset is balanced\n",
        "* All the results below are on the test dataset only - which the model was not exposed to during training / validation\n",
        "* Confusion matrix, precision , recall, F! score and ROC AUC in addition to accuracy"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "bOGh7-QRtPV5"
      },
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "\n",
        "conf_mx = confusion_matrix(y_test, Preds)\n",
        "\n",
        "TN = conf_mx[0,0]\n",
        "FP = conf_mx[0,1]\n",
        "FN = conf_mx[1,0]\n",
        "TP = conf_mx[1,1]\n",
        "\n",
        "print ('TN: ', TN)\n",
        "print ('FP: ', FP)\n",
        "print ('FN: ', FN)\n",
        "print ('TP: ', TP)\n",
        "\n",
        "recall = TP/(TP+FN)\n",
        "precision = TP/(TP+FP)\n",
        "\n",
        "print (recall, precision)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1vBOy9TvtPV5"
      },
      "cell_type": "code",
      "source": [
        "# Function to visualize the confusion matrix\n",
        "\n",
        "def plot_confusion_matrix(cm,target_names,title='Confusion matrix',cmap=None,\n",
        "                          normalize=False):\n",
        "    import itertools\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_fnv34d0tPV5"
      },
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(conf_mx,\n",
        "                      normalize    = False,\n",
        "                      target_names = ['resistant', 'sensistive'],\n",
        "                      title        = \"Confusion Matrix \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "GxutgQhNtPV6"
      },
      "cell_type": "code",
      "source": [
        "print ('precision ',precision_score(y_test, Preds))\n",
        "print ('recall ',recall_score(y_test, Preds) )\n",
        "print ('accuracy ',accuracy_score(y_test, Preds))\n",
        "print ('F1 score ',f1_score(y_test, Preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "EQrJv3f6tPV6"
      },
      "cell_type": "code",
      "source": [
        "# AUC/ROC curves should be used when there are roughly equal numbers of observations for each class\n",
        "# Precision-Recall curves should be used when there is a moderate to large class imbalance\n",
        "\n",
        "# calculate AUC\n",
        "auc = roc_auc_score(y_test, Preds)\n",
        "print('AUC: %.3f' % auc)\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, Preds)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.title('ROC ')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "G8UK6RydtPV6"
      },
      "cell_type": "code",
      "source": [
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, Preds)\n",
        "# calculate F1 score\n",
        "f1 = f1_score(y_test, Preds)\n",
        "# calculate average precision score\n",
        "ap = average_precision_score(y_test, Preds)\n",
        "print('f1=%.3f ap=%.3f' % (f1, ap))\n",
        "plt.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MpXK6k9ktPV6"
      },
      "cell_type": "markdown",
      "source": [
        "# Codons instead of nucleotides ... from 81% to 99%"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RFC_XYRJtPV6"
      },
      "cell_type": "code",
      "source": [
        "# From nucleotides to codons ... w/o considering the start / stop codons as the data is synthetic and may not have these\n",
        "\n",
        "DataCod = DataDf.copy()\n",
        "\n",
        "Codons = list(DataCod['genes'])\n",
        "print(len(Codons))\n",
        "\n",
        "for n in range(len(Codons)):\n",
        "    Codons[n] = list([Codons[n][i:i+3] for i in range(0, len(Codons[n]), 3)])\n",
        "\n",
        "DataCod['codons'] = Codons\n",
        "DataCod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "E2N_xEFBtPV6"
      },
      "cell_type": "code",
      "source": [
        "# Tokenize from codons to integers (sequences and then pad / truncate data)\n",
        "\n",
        "maxlen = 53 # cut off after this number of codons in a list\n",
        "\n",
        "max_words = 64 # considers only the top number of codons  in the dictionary (It finds 66 below because of 'a' and 'ga')\n",
        "max_features = max_words\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=max_words, char_level=True)\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(list(DataCod['codons']))\n",
        "sequences = tokenizer.texts_to_sequences(list(DataCod['codons']))\n",
        "word_index = tokenizer.word_index\n",
        "Xpad = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post', value=0)\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "print('word_index', word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "2e9XwzpxtPV6"
      },
      "cell_type": "code",
      "source": [
        "# Separate the label\n",
        "\n",
        "labels = np.asarray(DataCod['resistant'])\n",
        "print(Xpad.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "KSecUjDWtPV6"
      },
      "cell_type": "code",
      "source": [
        "# Check a sample\n",
        "\n",
        "rowNum = 37149\n",
        "print(DataCod['genes'][rowNum])\n",
        "print(DataCod['codons'][rowNum])\n",
        "print(sequences[rowNum])\n",
        "print(Xpad[rowNum])\n",
        "print(labels[rowNum])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "aZv2ZyxktPV7"
      },
      "cell_type": "code",
      "source": [
        "# Create train & val and test datasets with inital shuffle (as the original dataset may be arranged)\n",
        "\n",
        "training_samples = int(Xpad.shape[0] * 0.9)\n",
        "# The validation is being taken by keras - below\n",
        "# test = remaining\n",
        "\n",
        "indices = np.arange(Xpad.shape[0])\n",
        "np.random.shuffle(indices) # FOR TESTING PURPOSES comment it out - to keep indices as above\n",
        "\n",
        "Xpad = Xpad[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = Xpad[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_test = Xpad[training_samples: ]\n",
        "y_test = labels[training_samples: ]\n",
        "\n",
        "print('x_train', x_train.shape)\n",
        "print('y_train', y_train.shape)\n",
        "print('x_test', x_test.shape)\n",
        "print('y_test', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "uSqT0ef5tPV7"
      },
      "cell_type": "code",
      "source": [
        "# Model ... 64 CNN window 27 & Bidirectional GRU accuracy = 0.99\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(64, 1, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 27, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(3))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(128, 9, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Bidirectional(layers.GRU(32, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "4XjAf0LntPV7"
      },
      "cell_type": "code",
      "source": [
        "# Train / Validate model\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "epochs = 10,\n",
        "batch_size=32,\n",
        "validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7nx9ufkStPV7"
      },
      "cell_type": "code",
      "source": [
        "# Learning curves\n",
        "\n",
        "# VALIDATION LOSS curves\n",
        "\n",
        "plt.clf()\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, (len(history_dict['loss']) + 1))\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# VALIDATION ACCURACY curves\n",
        "\n",
        "plt.clf()\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']\n",
        "epochs = range(1, (len(history_dict['acc']) + 1))\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QNlmPIiMtPV7"
      },
      "cell_type": "code",
      "source": [
        "# Final Predict on test\n",
        "\n",
        "final_predictions = model.predict(x_test)\n",
        "print(final_predictions)\n",
        "\n",
        "# Modify the raw final_predictions - prediction probs  - into 0 and 1\n",
        "# Cutoff point = 0.5\n",
        "\n",
        "Preds = final_predictions.copy()\n",
        "print(len(Preds))\n",
        "\n",
        "Preds[ np.where( Preds >= 0.5 ) ] = 1\n",
        "Preds[ np.where( Preds < 0.5 ) ] = 0\n",
        "print(Preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "umSfd31GtPV7"
      },
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "\n",
        "conf_mx = confusion_matrix(y_test, Preds)\n",
        "\n",
        "TN = conf_mx[0,0]\n",
        "FP = conf_mx[0,1]\n",
        "FN = conf_mx[1,0]\n",
        "TP = conf_mx[1,1]\n",
        "\n",
        "print ('TN: ', TN)\n",
        "print ('FP: ', FP)\n",
        "print ('FN: ', FN)\n",
        "print ('TP: ', TP)\n",
        "\n",
        "recall = TP/(TP+FN)\n",
        "precision = TP/(TP+FP)\n",
        "\n",
        "print (recall, precision)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "LVPlzNH_tPV7"
      },
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(conf_mx,\n",
        "                      normalize    = False,\n",
        "                      target_names = ['resistant', 'sensistive'],\n",
        "                      title        = \"Confusion Matrix \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "dCQ6UWPetPV7"
      },
      "cell_type": "code",
      "source": [
        "# AUC/ROC curves should be used when there are roughly equal numbers of observations for each class\n",
        "# Precision-Recall curves should be used when there is a moderate to large class imbalance\n",
        "\n",
        "# calculate AUC\n",
        "auc = roc_auc_score(y_test, Preds)\n",
        "print('AUC: %.3f' % auc)\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, Preds)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.title('ROC ')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hMo9PVRbtPV7"
      },
      "cell_type": "code",
      "source": [
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, Preds)\n",
        "# calculate F1 score\n",
        "f1 = f1_score(y_test, Preds)\n",
        "# calculate average precision score\n",
        "ap = average_precision_score(y_test, Preds)\n",
        "print('f1=%.3f ap=%.3f' % (f1, ap))\n",
        "plt.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Predict antibiotic resistance w gene sequence",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}